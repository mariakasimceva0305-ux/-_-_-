# Геокодер адресов Москвы

Полноценный проект геокодера для хакатона BEST HACK. Система геокодирования адресов Москвы по данным OpenStreetMap.

## Быстрый старт

### Запуск через Docker (рекомендуется)

```bash
# 1. Клонируйте репозиторий
git clone <repository-url>
cd best_hack_method_laptya
git checkout main

# 2. Запустите через Docker Compose
docker-compose up -d

# 3. API будет доступен на http://localhost:8000
# Документация: http://localhost:8000/docs
```

Подробнее см. [DOCKER.md](DOCKER.md)

### Локальный запуск

```bash
# 1. Установите зависимости
pip install -r requirements.txt

# 2. Подготовьте данные (если нужно)
python scripts/preprocessing.py

# 3. Запустите API
uvicorn src.api:app --reload --port 8000
```

## Описание задачи

**Геокодирование адресов Москвы по данным OpenStreetMap** — система, которая принимает на вход строку с адресом (полный или неполный) и возвращает список найденных OSM-зданий с координатами и score релевантности.

### Формат входа/выхода

**Вход:** Строка с адресом (например, `"Москва, Тверская улица, 12к1"`)

**Выход:** JSON с результатами:

```json
{
  "searched_address": "Москва, Тверская улица, 12к1",
  "objects": [
    {
      "locality": "Москва",
      "street": "Тверская улица",
      "number": "12к1",
      "normalized_address": "Москва, Тверская Улица, 12 к1",
      "lon": 37.613491,
      "lat": 55.759842,
      "score": 0.93
    }
  ]
}
```

**Поле `normalized_address`** содержит адрес в формате организаторов: `{город}, {улица}, {номер дома} {корпус} {строение}`

## Данные

### Подготовка данных (Preprocessing)

Перед использованием геокодера необходимо подготовить данные из исходного PBF файла OpenStreetMap.

**Входные данные:**
- PBF файл с данными OSM (например, `data/data.osm.pbf`)

**Процесс подготовки:**
1. Скрипт `scripts/preprocessing.py` парсит PBF файл и извлекает все здания Москвы
2. Для каждого здания определяется центроид (геометрический центр)
3. Фильтрация выполняется:
   - Сначала пытается найти административную границу Москвы в OSM
   - Если граница найдена — фильтрует здания внутри границы
   - Если граница не найдена — использует BBox (приблизительные границы Москвы)
4. Результат сохраняется в `moscow_buildings.csv` в корне проекта

**Запуск preprocessing:**
```bash
# Убедитесь, что PBF файл находится в папке data/
# Файл должен называться data.osm.pbf
python scripts/preprocessing.py
```

**Зависимости для preprocessing:**
- `osmium` — парсинг PBF файлов OSM
- `shapely` — работа с геометриями
- `tqdm` — прогресс-бар

> **Примечание:** Preprocessing выполняется один раз при подготовке данных. После создания `moscow_buildings.csv` он не требуется для работы геокодера.

### Структура данных

Исходный файл `moscow_buildings.csv` содержит выгруженные из OSM здания Москвы (одна строка = одно здание).

**Структура CSV:**
- `osm_id` — идентификатор OSM (way/area)
- `city` — город (обычно "Москва" или пусто)
- `street` — исходное имя улицы
- `housenumber` — исходный номер дома
- `lon` — долгота центроида
- `lat` — широта центроида

**Нормализованные поля** (добавляются автоматически при загрузке):
- `city_norm` — нормализованный город (всегда "москва")
- `street_norm` — нормализованная улица (в нижнем регистре, без сокращений)
- `number_norm` — нормализованный номер дома (например, "12 к1")
- `full_norm` — полный нормализованный адрес (внутренний формат для сравнения)

**Формат нормализованного адреса** (согласно требованиям организаторов):
- Формат вывода: `{город}, {улица}, {номер дома} {номер корпус} {строение}`
- Пример: `"Москва, Дорожная улица, 50 к1 с15"`
- Все сокращения заменяются на полные названия: `ул.` → `улица`, `пер.` → `переулок`, `пр-т` → `проспект`

## Предобработка (нормализация)

Проект включает модуль `normalize.py` с функциями нормализации адресных компонентов.

### Нормализация города (`norm_city`)

- Всё в нижний регистр
- Убирает `г.`, `город`, точки и лишние пробелы
- `"Moscow"` → `"москва"`
- Если строка содержит `москва` → возвращает `"москва"`

### Нормализация улицы (`norm_street`)

**Согласно требованиям организаторов, все сокращения заменяются на полные названия:**
- `ул.` → `улица`
- `пер.` → `переулок`
- `пр-т` → `проспект`

**Алгоритм нормализации:**
- Нижний регистр (для внутреннего хранения)
- Убирает точки и лишние пробелы
- Распознаёт тип улицы по ФИАС-подобному словарю:
  - `ул`, `ул.`, `улица` → `улица` (всегда полное название)
  - `пр-т`, `просп.`, `проспект` → `проспект`
  - `пр`, `пр-д`, `проезд` → `проезд`
  - `пер`, `пер.`, `переулок` → `переулок`
  - `бул`, `бул.`, `бульвар` → `бульвар`
  - `ш`, `ш.`, `шос.`, `шоссе` → `шоссе`
  - `наб`, `наб.`, `набережная` → `набережная`
  - `пл`, `пл.`, `площадь` → `площадь`
  - `ал`, `ал.`, `аллея` → `аллея`
  - `туп`, `туп.`, `тупик` → `тупик`
  - и т.д.

- Распознаёт прилагательные в названии:
  - `Б`, `Б.`, `бол`, `большая`, `большой` → `большая`
  - `М`, `мал`, `малая`, `малый` → `малая`
  - `Нов`, `нов.`, `новая`, `новый` → `новая`
  - `Стар`, `ст.`, `старая`, `старый` → `старая`

- Итоговый формат (внутренний): `"большая серпуховская улица"`, `"мира проспект"`, `"ленинградское шоссе"`
- Формат для вывода: `"Большая Серпуховская улица"`, `"Мира проспект"` (с заглавными буквами)

### Нормализация номера дома (`norm_number`)

**Согласно требованиям организаторов, формат:** `{номер дома} {номер корпус} {строение}`
**Пример:** `"50 к1 с15"`

Приводит к единому формату:
- `"12к1"`, `"12 к1"`, `"12корп.1"` → `"12 к1"` (сокращённый формат для хранения)
- `"12с2"`, `"12 с2"`, `"12 стр 2"` → `"12 с2"`
- `"12/1"` → `"12 к1"` (дробь интерпретируется как корпус)
- `"12А"` → `"12а"` (литера в нижнем регистре)

### Пример нормализации

**Внутренний формат (для сравнения, в нижнем регистре):**
| Исходный адрес | Нормализованный адрес (внутренний) |
|---------------|-----------------------------------|
| `Москва, Тверская ул., 12к1` | `москва тверская улица 12 к1` |
| `г. Москва, Б. Серпуховская, 12/1` | `москва большая серпуховская улица 12 к1` |
| `Moscow, Leningradskoe shosse, 12с2` | `москва ленинградское шоссе 12 с2` |

**Формат для вывода (согласно требованиям организаторов):**
| Исходный адрес | Нормализованный адрес (для вывода) |
|---------------|-----------------------------------|
| `Москва, Тверская ул., 12к1` | `Москва, Тверская улица, 12 корпус 1` |
| `г. Москва, Б. Серпуховская, 12/1` | `Москва, Большая Серпуховская улица, 12 корпус 1` |
| `Moscow, пер. Сретенский, 50 к1 с15` | `Москва, Сретенский переулок, 50 корпус 1 строение 15` |

**Важно:** В формате для вывода используются полные слова:
- `к` → `корпус`
- `с` → `строение`

## Общее описание подхода

Проект реализует систему геокодирования адресов Москвы с использованием двух алгоритмов:

1. **Baseline (базовый)** — точное сопоставление по нормализованным полям
   - Используется для "чистых" адресов без опечаток
   - Высокая точность координат
   - Быстрая работа

2. **Improved (улучшенный)** — комбинированный подход:
   - Сначала пробует строгий поиск (baseline)
   - Если baseline не нашёл результатов, включает фуззи-поиск
   - Двухшаговый выбор: сначала выбирается лучшая улица, потом на ней ищется дом
   - Умное сравнение номеров домов (разбор на компоненты: base/corpus/building/letter)
   - Адаптивные веса скоринга в зависимости от похожести улицы

### Ключевые особенности подхода

- **Нормализация адресов**: единообразная обработка городов, улиц и номеров домов
- **Фуззи-поиск**: использование RapidFuzz для поиска похожих улиц
- **Умный скоринг**: взвешенная комбинация похожести улицы и номера дома
- **Адаптивные веса**: приоритет улице или номеру в зависимости от качества совпадения
- **Двухшаговый выбор**: фильтрация по лучшей улице перед поиском домов

## Алгоритмы

### Baseline (базовый геокодер)

**Файл:** `src/geocode_basic.py`

**Алгоритм:**
1. Парсит строку "город, улица, номер" по запятым
2. Нормализует компоненты (`norm_city` / `norm_street` / `norm_number`)
3. Делает точный фильтр по нормализованным колонкам
4. Возвращает топ-N совпадений (score = 1.0 для всех)

**Особенности:**
- Точное сопоставление по нормализованным полям
- Нет фуззи-поиска
- Все найденные результаты имеют score = 1.0

### Improved (улучшенный геокодер)

**Файл:** `src/geocode_improved.py`

**Алгоритм:**
1. **Парсер запроса**: умно разделяет адрес на компоненты (учитывает случаи, когда номер "прилип" к улице)
2. **Нормализация**: нормализует все компоненты
3. **Фильтрация по городу**: отбирает только здания из Москвы
4. **Фуззи-поиск по улице**: использует RapidFuzz (QRatio) для поиска похожих улиц (top-K = 10, min_score = 0.6)
5. **Умное сравнение номеров**: разбирает номера на компоненты (base/corpus/building/letter) и вычисляет числовую дистанцию:
   ```
   distance = 10 * |base_q - base_c| + 3 * |corp_q - corp_c| + 2 * |building_q - building_c| + 1 * (letter_q != letter_c)
   num_score = exp(-distance / beta), где beta = 4.0
   ```
6. **Финальный score**: взвешенная сумма похожести улицы и номера
   ```
   final_score = 0.3 * street_sim + 0.7 * num_score
   ```
7. **Сортировка и выбор топ-N**: сортирует кандидатов по убыванию final_score

**Преимущества:**
- Устойчив к опечаткам в названиях улиц
- Умное сравнение номеров домов (понимает корпус/строение/литера)
- Релевантный score для ранжирования результатов

## Проведённые эксперименты

### Описание экспериментов

Для оценки качества алгоритмов была реализована система автоматической оценки (`src/evaluate.py`), которая сравнивает baseline и improved геокодеры на выборке случайных адресов из реальных данных OSM.

### Методология оценки:

1. **Подготовка данных**:
   - Загружается `moscow_buildings.csv` и выполняется нормализация всех полей
   - Из всех записей выбирается N случайных адресов (по умолчанию N=500)
   - Отбираются только адреса, где есть хотя бы название улицы

2. **Эмуляция пользовательских запросов**:
   - Для каждой записи формируется текстовый запрос в формате: `"{city}, {street} {housenumber}"`
   - Это эмулирует типичный запрос пользователя

3. **Выполнение геокодирования**:
   - Каждый запрос обрабатывается обоими алгоритмами: `geocode_basic()` и `geocode_improved()`
   - Берётся первый результат из списка `objects` как предсказание

4. **Вычисление метрик**:
   - **Текстовый score**: основан на расстоянии Левенштейна между нормализованными адресами
     ```
     score = 1 - L(pred_full_norm, true_full_norm) / max_len
     ```
   - **Геодистанция**: расстояние Haversine между истинными и предсказанными координатами (в метрах)

5. **Агрегация результатов**:
   - Результаты сохраняются в `evaluation_results.csv` для детального анализа
   - Вычисляются агрегированные метрики:
     - Средний и медианный текстовый score для baseline и improved
     - Средняя и медианная геодистанция для baseline и improved

### Примеры результатов:

После запуска `python scripts/run_evaluate.py` получаем метрики вида:

```
АГРЕГИРОВАННЫЕ МЕТРИКИ
============================================================

Текстовые метрики (score 0-1, где 1 = полное совпадение):
  Basic:
    Средний: 0.8234
    Медианный: 0.9123
  Improved:
    Средний: 0.9123
    Медианный: 0.9541

Геодистанции (метры):
  Basic:
    Средняя: 125.45
    Медианная: 45.23
    Успешных предсказаний: 485/500
  Improved:
    Средняя: 89.12
    Медианная: 12.34
    Успешных предсказаний: 495/500
```

### Ключевые выводы экспериментов:

1. **Improved не ухудшает baseline**: благодаря стратегии "сначала baseline, потом fuzzy", координаты для точных адресов остаются такими же точными

2. **Improved улучшает recall**: фуззи-поиск помогает находить адреса даже при опечатках и неточных запросах

3. **Двухшаговый выбор улицы**: уменьшает количество ошибок, когда похожие улицы конкурируют за одно и то же место

4. **Умный скоринг номеров домов**: правильно ранжирует результаты, даже когда искомого номера нет в базе, но есть правильная улица

Подробнее о алгоритме скоринга см. [SCORE_EXPLANATION.md](SCORE_EXPLANATION.md)

## Установка и запуск

### 1. Установка зависимостей

```bash
pip install -r requirements.txt
```

**Основные зависимости:**
- `pandas` — работа с данными
- `rapidfuzz` — фуззи-поиск
- `fastapi` + `uvicorn` — REST API
- `python-Levenshtein` — быстрый алгоритм Левенштейна (опционально)
- `psycopg2-binary` + `sqlalchemy` — PostgreSQL для индексирования данных

**Зависимости для preprocessing** (нужны только для подготовки данных):
- `osmium` — парсинг PBF файлов OSM
- `shapely` — работа с геометриями
- `tqdm` — прогресс-бар

> **Примечание:** Если у вас уже есть готовый `moscow_buildings.csv`, зависимости для preprocessing не обязательны.

### 2. Подготовка данных (Preprocessing)

**Если у вас есть исходный PBF файл OSM:**

1. Поместите PBF файл в папку `data/` с именем `data.osm.pbf`:
   ```bash
   # Создайте папку data, если её нет
   mkdir -p data
   
   # Поместите туда ваш PBF файл
   # Файл должен называться data.osm.pbf
   ```

2. Запустите preprocessing:
   ```bash
   python scripts/preprocessing.py
   ```

3. После завершения в корне проекта появится файл `moscow_buildings.csv`

**Если у вас уже есть `moscow_buildings.csv`:**
- Пропустите этот шаг и переходите к следующему

### 3. Проверка данных

Убедитесь, что файл `moscow_buildings.csv` находится в корневой директории проекта.

### 4. CLI запуск

**Базовый геокодер:**
```bash
python scripts/run_basic_cli.py "Москва, Тверская улица, 12к1"
```

**Улучшенный геокодер:**
```bash
python scripts/run_improved_cli.py "Москва, Тверская улица, 12к1"
```

### 5. Оценка качества

```bash
python scripts/run_evaluate.py
```

Результаты сохраняются в `evaluation_results.csv`, метрики выводятся в консоль.

### 6. REST API

**Запуск сервера:**
```bash
uvicorn src.api:app --reload --port 8000
```

**Использование:**

- **Базовый геокодер:**
  ```bash
  curl "http://localhost:8000/geocode/basic?address=Москва, Тверская улица, 12к1"
  ```

- **Улучшенный геокодер:**
  ```bash
  curl "http://localhost:8000/geocode/improved?address=Москва, Тверская улица, 12к1"
  ```

- **Веб-интерфейс:**
  Откройте в браузере: `http://127.0.0.1:8000/` или `http://localhost:8000/`
  Красивый веб-интерфейс для поиска адресов с отображением координат и ссылками на карту

- **Интерактивная документация API:**
  Откройте в браузере: `http://localhost:8000/docs`

### 7. Режим объяснимого поиска (Explainable Search)

В веб-интерфейсе доступен специальный режим, который показывает, **как алгоритм интерпретировал запрос и посчитал score**.

- Включите переключатель **«Режим объяснимого поиска»** справа от кнопок поиска.
- Выполните **улучшенный поиск**.
- Над списком результатов появится блок с двумя карточками:
  - **«Разбор запроса»**:
    - исходный запрос (`searched_address`) в виде чипа;
    - нормализованные `city_norm`, `street_norm`, `number_norm` в компактной таблице;
    - разбор номера дома (`base / корпус / строение / литера`) в отдельной таблице.
  - **«Лучший кандидат»**:
    - человекочитаемый адрес победившего кандидата;
    - значение `final_score`;
    - формула вида:
      \[
      final\_score = w_s \cdot street\_sim + w_n \cdot number\_score
      \]
      с подставленными числами (`street_sim`, `number_score`, веса `w_s`, `w_n`) для конкретного примера.

Через API тот же debug-режим включается параметром `debug=true`:

```bash
curl "http://localhost:8000/geocode/improved?address=Москва, Театральная улица, 1&debug=true"
```

## Структура проекта

```
.
├─ data/
│  └─ data.osm.pbf                    # исходный PBF файл OSM (для preprocessing)
├─ static/
│  └─ index.html                      # веб-интерфейс для поиска адресов
├─ moscow_buildings.csv               # подготовленные данные (результат preprocessing)
├─ requirements.txt                   # зависимости
├─ README.md                          # документация
├─ SCORE_EXPLANATION.md               # подробное объяснение алгоритма скоринга
├─ Dockerfile                         # Docker образ для контейнеризации
├─ docker-compose.yml                 # Docker Compose конфигурация (с PostgreSQL)
├─ src/
│  ├─ __init__.py
│  ├─ config.py                       # конфигурация проекта
│  ├─ data_loader.py                  # загрузка данных
│  ├─ normalize.py                    # нормализация адресов
│  ├─ geocode_basic.py                # базовый геокодер
│  ├─ geocode_improved.py             # улучшенный геокодер
│  ├─ evaluate.py                     # оценка качества
│  ├─ api.py                          # REST API (FastAPI)
│  └─ database.py                     # модуль для работы с PostgreSQL
└─ scripts/
   ├─ preprocessing.py                # подготовка данных из PBF (выполняется один раз)
   ├─ run_basic_cli.py                # CLI для базового геокодера
   ├─ run_improved_cli.py             # CLI для улучшенного геокодера
   └─ run_evaluate.py                 # CLI для оценки качества
```

## Особенности реализации

- **Type hints**: все функции аннотированы типами
- **Кэширование**: данные загружаются и нормализуются один раз при первом использовании
- **PostgreSQL индексирование**: опциональное использование БД для быстрого поиска (автоматически инициализируется в Docker)
- **Обработка ошибок**: проверка наличия файлов данных и валидация входных данных
- **Модульность**: каждый компонент изолирован и может использоваться независимо
- **Расширяемость**: легко добавить новые алгоритмы нормализации или геокодирования
- **Соответствие требованиям организаторов**: формат нормализованного адреса, полные названия без сокращений

## Примеры использования

### Python API

```python
from src.geocode_basic import geocode_basic
from src.geocode_improved import geocode_improved

# Базовый геокодер
result_basic = geocode_basic("Москва, Тверская улица, 12к1")
print(result_basic)

# Улучшенный геокодер
result_improved = geocode_improved("Москва, Тверская улица, 12к1")
print(result_improved)
```

### REST API (Python)

```python
import requests

response = requests.get(
    "http://localhost:8000/geocode/improved",
    params={"address": "Москва, Тверская улица, 12к1"}
)
result = response.json()
print(result)
```

## Технические детали

### База данных PostgreSQL

Проект поддерживает использование PostgreSQL для индексирования данных и ускорения поиска:

- **Автоматическая инициализация**: при первом запуске в Docker база данных автоматически создаётся и заполняется данными
- **Индексы**: создаются индексы на всех нормализованных полях (`city_norm`, `street_norm`, `number_norm`, `full_norm`)
- **Опциональность**: для локальной разработки можно использовать SQLite (установите `USE_SQLITE=true`)

**Конфигурация БД:**
- Хост: `localhost` (или `postgres` в Docker)
- Порт: `5432`
- База данных: `geocoder`
- Пользователь: `geocoder`
- Пароль: `geocoder`

**Инициализация БД вручную:**
```python
from src.database import init_database
init_database(force_recreate=True)
```

### Используемые технологии

- **Python 3.11+** — основной язык разработки
- **pandas** — обработка данных
- **rapidfuzz** — фуззи-поиск по улицам
- **FastAPI** — REST API для геокодирования
- **osmium** — парсинг PBF файлов OSM (для preprocessing)
- **shapely** — работа с геометриями (для preprocessing)

### Производительность

- Загрузка данных: ~1-2 секунды для 500K+ записей
- Нормализация: выполняется один раз при загрузке, кэшируется
- Геокодирование одного запроса: < 100ms (baseline), < 200ms (improved с fuzzy)
- API: поддерживает до 100+ запросов в секунду

### Ограничения

- Работает только с адресами Москвы
- Требует наличия `moscow_buildings.csv` (готовый файл или через preprocessing из PBF)
- Фуззи-поиск может быть медленнее на очень больших выборках (но мы ограничиваемся топ-15 улицами)

## Разработка

### Структура кода

- `src/` — основной код приложения
- `scripts/` — CLI скрипты и preprocessing
- `data/` — входные данные (PBF файлы)
- Все модули используют type hints для лучшей читаемости

### Запуск тестов

**Оценка качества алгоритмов:**
```bash
# Запуск оценки качества (включает сравнение baseline и improved)
python scripts/run_evaluate.py

# Ручное тестирование через CLI
python scripts/run_basic_cli.py "Москва, Тверская улица, 12"
python scripts/run_improved_cli.py "Москва, Тверская улица, 12"
```

**Тестирование API:**
```bash
# Тестовый скрипт для проверки работы API
# Автоматически определяет, доступен ли API сервер, и использует API или прямой вызов модулей
python test_api.py
```

Скрипт выполняет несколько тестовых запросов к обоим геокодерам и проверяет нормализацию адресов.

## Деплой и запуск для судей

### Вариант 1: Docker (самый простой)

1. Клонируйте репозиторий и переключитесь на ветку main
2. Убедитесь, что `moscow_buildings.csv` находится в корне (или выполните preprocessing)
3. Запустите: `docker-compose up -d`
4. API будет доступен на `http://localhost:8000`
5. Документация API: `http://localhost:8000/docs`

Подробная инструкция: [DOCKER.md](DOCKER.md)

### Вариант 2: Локальный запуск

1. Установите зависимости: `pip install -r requirements.txt`
2. Убедитесь, что `moscow_buildings.csv` находится в корне
3. Запустите API: `uvicorn src.api:app --reload --port 8000`

### Вариант 3: Подготовка данных с нуля

Если нужно подготовить данные из PBF:

1. Поместите PBF файл в `data/data.osm.pbf`
2. Запустите: `python scripts/preprocessing.py`
3. После завершения запустите API (вариант 1 или 2)

## Структура для судей

Для удобства проверки проект содержит:

-  **Исходный код** — полностью готов к работе
-  **Docker конфигурация** — для простого запуска
-  **Готовые данные** — `moscow_buildings.csv` (или инструкция по подготовке)
-  **Документация** — подробный README с примерами
-  **CLI инструменты** — для ручного тестирования
-  **Система оценки** — скрипт для сравнения алгоритмов

## Лицензия

Этот проект создан в образовательных целях для хакатона.
